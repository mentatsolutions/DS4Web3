{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpY6w08VKBUl"
   },
   "source": [
    "## Installing Kaggle and Downloading Ethereum Fraud Detection Dataset\n",
    "\n",
    "The code `!pip install kaggle` will install the Kaggle API on the computer. To run the this cell you will need to provide the Kaggle user and password in json format in the same directory of this notebook. Please follow the tutorial available in the Further Reading section at the end of the Chapter. \n",
    "The code `!mkdir ~/.kaggle` will create a directory called `.kaggle` in the user's home directory, `!cp kaggle.json ~/.kaggle/` copy the `kaggle.json` file to the `.kaggle` directory and `!chmod 600 ~/.kaggle/kaggle.json` sets the permissions of the `kaggle.json` file to read-only. \n",
    "\n",
    "With `!kaggle datasets download vagifa/ethereum-frauddetection-dataset` download the Ethereum Fraud Detection Dataset from Kaggle and with `!unzip ethereum-frauddetection-dataset.zip` unzip it for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVW0s7Y_htRo",
    "outputId": "ae232533-9ff6-40be-f193-5a5e22274953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
      "Downloading ethereum-frauddetection-dataset.zip to /content\n",
      "  0% 0.00/923k [00:00<?, ?B/s]\n",
      "100% 923k/923k [00:00<00:00, 119MB/s]\n",
      "Archive:  ethereum-frauddetection-dataset.zip\n",
      "  inflating: transaction_dataset.csv  \n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download vagifa/ethereum-frauddetection-dataset\n",
    "!unzip ethereum-frauddetection-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDHjHd-zKNG5"
   },
   "source": [
    "## Imports\n",
    "\n",
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5Bx2lVl1kUjC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgZfRAHOK0Ex"
   },
   "source": [
    "## Read the Dataset\n",
    "\n",
    "Define a list of columns to be used and read the dataset from the file `transaction_dataset.csv` downloaded from Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "qLUCoaYskZXJ",
    "outputId": "b38030ca-803d-49e7-ec6d-9d8a014b9b1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-d44d3c5b-b05a-45c6-ba81-2bfdfdbe49e4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLAG</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Sent tnx</th>\n",
       "      <th>Received Tnx</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total Ether sent</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>Total ERC20 tnxs</th>\n",
       "      <th>ERC20 total Ether received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1093.71</td>\n",
       "      <td>721</td>\n",
       "      <td>89</td>\n",
       "      <td>40</td>\n",
       "      <td>6.589513</td>\n",
       "      <td>1.200681</td>\n",
       "      <td>810</td>\n",
       "      <td>865.691093</td>\n",
       "      <td>586.466675</td>\n",
       "      <td>265.0</td>\n",
       "      <td>3.558854e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2958.44</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>0.032844</td>\n",
       "      <td>102</td>\n",
       "      <td>3.087297</td>\n",
       "      <td>3.085478</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.034283e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2434.02</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.358906</td>\n",
       "      <td>1.794308</td>\n",
       "      <td>12</td>\n",
       "      <td>3.588616</td>\n",
       "      <td>3.589057</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.215121e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15785.09</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>99.488840</td>\n",
       "      <td>70.001834</td>\n",
       "      <td>34</td>\n",
       "      <td>1750.045862</td>\n",
       "      <td>895.399559</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.711105e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10707.77</td>\n",
       "      <td>4598</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2.671095</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>4619</td>\n",
       "      <td>104.318883</td>\n",
       "      <td>53.421897</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.628297e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d44d3c5b-b05a-45c6-ba81-2bfdfdbe49e4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-0084cffd-e875-4d30-94eb-8d30e5133e8f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0084cffd-e875-4d30-94eb-8d30e5133e8f')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-0084cffd-e875-4d30-94eb-8d30e5133e8f button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d44d3c5b-b05a-45c6-ba81-2bfdfdbe49e4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d44d3c5b-b05a-45c6-ba81-2bfdfdbe49e4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   FLAG  Avg min between received tnx  Sent tnx  Received Tnx  \\\n",
       "0     0                       1093.71       721            89   \n",
       "1     0                       2958.44        94             8   \n",
       "2     0                       2434.02         2            10   \n",
       "3     0                      15785.09        25             9   \n",
       "4     0                      10707.77      4598            20   \n",
       "\n",
       "   Unique Received From Addresses  avg val received  avg val sent  \\\n",
       "0                              40          6.589513      1.200681   \n",
       "1                               5          0.385685      0.032844   \n",
       "2                              10          0.358906      1.794308   \n",
       "3                               7         99.488840     70.001834   \n",
       "4                               7          2.671095      0.022688   \n",
       "\n",
       "   total transactions (including tnx to create contract  total Ether sent  \\\n",
       "0                                                810           865.691093   \n",
       "1                                                102             3.087297   \n",
       "2                                                 12             3.588616   \n",
       "3                                                 34          1750.045862   \n",
       "4                                               4619           104.318883   \n",
       "\n",
       "   total ether received   Total ERC20 tnxs   ERC20 total Ether received  \n",
       "0            586.466675              265.0                 3.558854e+07  \n",
       "1              3.085478                8.0                 4.034283e+02  \n",
       "2              3.589057                8.0                 5.215121e+02  \n",
       "3            895.399559               14.0                 1.711105e+04  \n",
       "4             53.421897               42.0                 1.628297e+05  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['FLAG', 'Avg min between received tnx','Sent tnx', 'Received Tnx', 'Unique Received From Addresses',\n",
    "        'avg val received','avg val sent', 'total transactions (including tnx to create contract','total Ether sent', 'total ether received',\n",
    "      ' Total ERC20 tnxs', ' ERC20 total Ether received']\n",
    "df= pd.read_csv (\"transaction_dataset.csv\", usecols=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUJUmj7RrGY9",
    "outputId": "1709aa75-6880-4dfa-d166-726b4db8043a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9841 entries, 0 to 9840\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   FLAG                                                  9841 non-null   int64  \n",
      " 1   Avg min between received tnx                          9841 non-null   float64\n",
      " 2   Sent tnx                                              9841 non-null   int64  \n",
      " 3   Received Tnx                                          9841 non-null   int64  \n",
      " 4   Unique Received From Addresses                        9841 non-null   int64  \n",
      " 5   avg val received                                      9841 non-null   float64\n",
      " 6   avg val sent                                          9841 non-null   float64\n",
      " 7   total transactions (including tnx to create contract  9841 non-null   int64  \n",
      " 8   total Ether sent                                      9841 non-null   float64\n",
      " 9   total ether received                                  9841 non-null   float64\n",
      " 10   Total ERC20 tnxs                                     9012 non-null   float64\n",
      " 11   ERC20 total Ether received                           9012 non-null   float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 922.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7ZLE7YNK_bE"
   },
   "source": [
    "## Dropping Null Values\n",
    "\n",
    "Drop all rows with null values in the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l9HkYPejvjZ7"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['Avg min between received tnx',\n",
    "       'Sent tnx', 'Received Tnx', 'Unique Received From Addresses',\n",
    "       'avg val received', 'avg val sent',\n",
    "       'total transactions (including tnx to create contract',\n",
    "       'total Ether sent', 'total ether received', ' Total ERC20 tnxs',\n",
    "       ' ERC20 total Ether received'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dependent and independent variables\n",
    "\n",
    "The `X` variable contains all the columns from the dataframe except for the `FLAG` column, while the `y` variable contains only the `FLAG` column also known as labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8R1wSVDsrM_o"
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"FLAG\"]\n",
    "y= df[['FLAG']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data\n",
    "\n",
    "Create a RobustScaler object. The `X=scaler.fit_transform(X)` will use the RobustScaler object to scale the data in the `X` variable. This scaling will help ensure that all the features in the data have the same range, which can help improve the accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3C_5DUsPaCMZ"
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "on3S9bRjLH1N"
   },
   "source": [
    "## Splitting Data\n",
    "\n",
    "Split the data into training and testing sets. The `stratify` parameter ensures that the proportion of labels in the training and testing sets is the same as the proportion of labels in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ffx8PXzStOzC"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4S95LNyuzNK",
    "outputId": "1064653a-abaf-428e-a052-1e85492b8aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6038, 11)\n",
      "(6038, 1)\n",
      "(2974, 11)\n",
      "(2974, 1)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0orr1CdTRBA"
   },
   "source": [
    "## Build the Model\n",
    "\n",
    "Create a Sequential model with four layers, the first layer taking the shape of the training data, and the last layer having a sigmoid activation function. Compile the model by defining the loss function as Binary Crossentropy and the metrics as Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxvneL3X2jG-",
    "outputId": "cc512c19-19b1-4c89-ea90-af4eb3f9eb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 30)                360       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 731\n",
      "Trainable params: 731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "metrics = [\n",
    " #   keras.metrics.FalseNegatives(name=\"fn\"),\n",
    " #   keras.metrics.FalsePositives(name=\"fp\"),\n",
    " #   keras.metrics.TrueNegatives(name=\"tn\"),\n",
    " #   keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=True , reduction='sum')\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-2), loss=loss_function, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF7phkXgLNJG"
   },
   "source": [
    "#### Setting Class Weights\n",
    "\n",
    "Set the class weights for the model. This is used to adjust the weights of the classes in the model to account for imbalanced datasets.\n",
    "The formula for class_weight is `total observations / (number of classes * observations in class)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aCcGqe6WGxkP"
   },
   "outputs": [],
   "source": [
    "#class_weight={1:3.34 ,0:0.59}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Train the model using the training data (X_train and y_train) and the validation data (X_test and y_test). The model will be trained for 90 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EqrxaSc5CdtA",
    "outputId": "d095d60a-956a-4239-b935-b42567390715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/189 [============================>.] - ETA: 0s - loss: 501.7614 - precision: 0.8741 - recall: 0.4215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 4s 8ms/step - loss: 486.7880 - precision: 0.8733 - recall: 0.4347 - val_loss: 7.0528 - val_precision: 0.8788 - val_recall: 0.7803\n",
      "Epoch 2/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 8.1313 - precision: 0.8704 - recall: 0.7058 - val_loss: 4.9093 - val_precision: 0.8981 - val_recall: 0.7511\n",
      "Epoch 3/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.8393 - precision: 0.8778 - recall: 0.7389 - val_loss: 4.1952 - val_precision: 0.9134 - val_recall: 0.7803\n",
      "Epoch 4/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.3870 - precision: 0.8984 - recall: 0.7633 - val_loss: 3.9093 - val_precision: 0.9291 - val_recall: 0.7937\n",
      "Epoch 5/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 5.9534 - precision: 0.8960 - recall: 0.7721 - val_loss: 3.8150 - val_precision: 0.9034 - val_recall: 0.8386\n",
      "Epoch 6/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.2080 - precision: 0.9026 - recall: 0.8097 - val_loss: 3.7030 - val_precision: 0.9244 - val_recall: 0.8229\n",
      "Epoch 7/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 6.0356 - precision: 0.9071 - recall: 0.7777 - val_loss: 3.8126 - val_precision: 0.9286 - val_recall: 0.8161\n",
      "Epoch 8/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.0570 - precision: 0.9140 - recall: 0.7998 - val_loss: 3.6621 - val_precision: 0.9293 - val_recall: 0.8251\n",
      "Epoch 9/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.7973 - precision: 0.9153 - recall: 0.7533 - val_loss: 4.2653 - val_precision: 0.9037 - val_recall: 0.7578\n",
      "Epoch 10/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 4.1605 - precision: 0.9150 - recall: 0.7743 - val_loss: 3.8146 - val_precision: 0.9093 - val_recall: 0.8094\n",
      "Epoch 11/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.8672 - precision: 0.9265 - recall: 0.7942 - val_loss: 3.4494 - val_precision: 0.9221 - val_recall: 0.8229\n",
      "Epoch 12/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.6505 - precision: 0.9269 - recall: 0.7998 - val_loss: 3.6026 - val_precision: 0.9034 - val_recall: 0.8386\n",
      "Epoch 13/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.6774 - precision: 0.9334 - recall: 0.8064 - val_loss: 3.5110 - val_precision: 0.9080 - val_recall: 0.8408\n",
      "Epoch 14/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.5270 - precision: 0.9334 - recall: 0.8064 - val_loss: 3.4672 - val_precision: 0.9318 - val_recall: 0.8274\n",
      "Epoch 15/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 8.2527 - precision: 0.9316 - recall: 0.7987 - val_loss: 3.6746 - val_precision: 0.9302 - val_recall: 0.8363\n",
      "Epoch 16/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.6874 - precision: 0.9381 - recall: 0.8042 - val_loss: 3.5956 - val_precision: 0.9091 - val_recall: 0.8520\n",
      "Epoch 17/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.5588 - precision: 0.9386 - recall: 0.8119 - val_loss: 3.6090 - val_precision: 0.9280 - val_recall: 0.8386\n",
      "Epoch 18/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.4849 - precision: 0.9449 - recall: 0.8164 - val_loss: 3.3587 - val_precision: 0.9236 - val_recall: 0.8408\n",
      "Epoch 19/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.4296 - precision: 0.9397 - recall: 0.8108 - val_loss: 3.7912 - val_precision: 0.9356 - val_recall: 0.8139\n",
      "Epoch 20/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.3687 - precision: 0.9434 - recall: 0.8119 - val_loss: 3.8527 - val_precision: 0.9311 - val_recall: 0.8184\n",
      "Epoch 21/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.5403 - precision: 0.9374 - recall: 0.8119 - val_loss: 3.4413 - val_precision: 0.9320 - val_recall: 0.8296\n",
      "Epoch 22/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.4198 - precision: 0.9484 - recall: 0.8131 - val_loss: 3.7448 - val_precision: 0.9271 - val_recall: 0.8274\n",
      "Epoch 23/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.3883 - precision: 0.9402 - recall: 0.8175 - val_loss: 3.7109 - val_precision: 0.9256 - val_recall: 0.8363\n",
      "Epoch 24/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.3315 - precision: 0.9495 - recall: 0.8108 - val_loss: 3.8059 - val_precision: 0.9416 - val_recall: 0.8318\n",
      "Epoch 25/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.3270 - precision: 0.9473 - recall: 0.8153 - val_loss: 4.4108 - val_precision: 0.9323 - val_recall: 0.8341\n",
      "Epoch 26/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.3175 - precision: 0.9459 - recall: 0.8131 - val_loss: 3.9619 - val_precision: 0.9277 - val_recall: 0.8341\n",
      "Epoch 27/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.2732 - precision: 0.9457 - recall: 0.8097 - val_loss: 3.3401 - val_precision: 0.9280 - val_recall: 0.8386\n",
      "Epoch 28/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.3042 - precision: 0.9447 - recall: 0.8131 - val_loss: 3.1967 - val_precision: 0.9294 - val_recall: 0.8565\n",
      "Epoch 29/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.3533 - precision: 0.9436 - recall: 0.8142 - val_loss: 3.5867 - val_precision: 0.9258 - val_recall: 0.8117\n",
      "Epoch 30/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.3773 - precision: 0.9359 - recall: 0.8075 - val_loss: 3.2745 - val_precision: 0.9195 - val_recall: 0.8453\n",
      "Epoch 31/90\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 3.2313 - precision: 0.9487 - recall: 0.8175 - val_loss: 3.2873 - val_precision: 0.9221 - val_recall: 0.8498\n",
      "Epoch 32/90\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 3.2365 - precision: 0.9451 - recall: 0.8186 - val_loss: 3.4958 - val_precision: 0.9450 - val_recall: 0.8094\n",
      "Epoch 33/90\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 3.2442 - precision: 0.9501 - recall: 0.8219 - val_loss: 3.9810 - val_precision: 0.9744 - val_recall: 0.7691\n",
      "Epoch 34/90\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 3.1791 - precision: 0.9450 - recall: 0.8175 - val_loss: 4.4376 - val_precision: 0.9275 - val_recall: 0.8318\n",
      "Epoch 35/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.0553 - precision: 0.9505 - recall: 0.8285 - val_loss: 3.8584 - val_precision: 0.9515 - val_recall: 0.8363\n",
      "Epoch 36/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.0752 - precision: 0.9540 - recall: 0.8263 - val_loss: 4.8715 - val_precision: 0.9495 - val_recall: 0.8430\n",
      "Epoch 37/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.4580 - precision: 0.9418 - recall: 0.8053 - val_loss: 4.5964 - val_precision: 0.9202 - val_recall: 0.8274\n",
      "Epoch 38/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.1626 - precision: 0.9520 - recall: 0.8119 - val_loss: 6.1129 - val_precision: 0.9296 - val_recall: 0.8296\n",
      "Epoch 39/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.0206 - precision: 0.9551 - recall: 0.8241 - val_loss: 13.0163 - val_precision: 0.9248 - val_recall: 0.8274\n",
      "Epoch 40/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 6.4309 - precision: 0.9328 - recall: 0.8142 - val_loss: 3.4295 - val_precision: 0.9104 - val_recall: 0.8655\n",
      "Epoch 41/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.2936 - precision: 0.9480 - recall: 0.8064 - val_loss: 3.2814 - val_precision: 0.9078 - val_recall: 0.8610\n",
      "Epoch 42/90\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 3.2819 - precision: 0.9538 - recall: 0.8219 - val_loss: 3.1891 - val_precision: 0.9367 - val_recall: 0.8632\n",
      "Epoch 43/90\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 3.0765 - precision: 0.9566 - recall: 0.8296 - val_loss: 3.2654 - val_precision: 0.9404 - val_recall: 0.8498\n",
      "Epoch 44/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.5244 - precision: 0.9505 - recall: 0.8075 - val_loss: 3.3376 - val_precision: 0.9651 - val_recall: 0.8072\n",
      "Epoch 45/90\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 3.2731 - precision: 0.9516 - recall: 0.8042 - val_loss: 3.2992 - val_precision: 0.9231 - val_recall: 0.8341\n",
      "Epoch 46/90\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 3.2028 - precision: 0.9531 - recall: 0.8086 - val_loss: 3.2999 - val_precision: 0.9199 - val_recall: 0.8498\n",
      "Epoch 47/90\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 3.3024 - precision: 0.9630 - recall: 0.8064 - val_loss: 3.9031 - val_precision: 0.9372 - val_recall: 0.8363\n",
      "Epoch 48/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.2329 - precision: 0.9535 - recall: 0.8175 - val_loss: 3.1581 - val_precision: 0.9756 - val_recall: 0.8072\n",
      "Epoch 49/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.2090 - precision: 0.9607 - recall: 0.8108 - val_loss: 3.1827 - val_precision: 0.9348 - val_recall: 0.8363\n",
      "Epoch 50/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.1085 - precision: 0.9623 - recall: 0.8197 - val_loss: 3.2619 - val_precision: 0.9634 - val_recall: 0.8251\n",
      "Epoch 51/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.0543 - precision: 0.9662 - recall: 0.8219 - val_loss: 3.6611 - val_precision: 0.9536 - val_recall: 0.8296\n",
      "Epoch 52/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3845.3850 - precision: 0.9538 - recall: 0.7765 - val_loss: 3.7716 - val_precision: 0.9512 - val_recall: 0.7870\n",
      "Epoch 53/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.8184 - precision: 0.9429 - recall: 0.7677 - val_loss: 3.4466 - val_precision: 0.9266 - val_recall: 0.8206\n",
      "Epoch 54/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.6620 - precision: 0.9491 - recall: 0.7843 - val_loss: 3.4421 - val_precision: 0.9357 - val_recall: 0.8161\n",
      "Epoch 55/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.5307 - precision: 0.9535 - recall: 0.7931 - val_loss: 3.5954 - val_precision: 0.9264 - val_recall: 0.8184\n",
      "Epoch 56/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.4605 - precision: 0.9498 - recall: 0.7954 - val_loss: 7.8112 - val_precision: 0.9284 - val_recall: 0.8139\n",
      "Epoch 57/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.4983 - precision: 0.9457 - recall: 0.7898 - val_loss: 7.2704 - val_precision: 0.9501 - val_recall: 0.8117\n",
      "Epoch 58/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 4.2049 - precision: 0.9588 - recall: 0.7987 - val_loss: 5.4756 - val_precision: 0.9481 - val_recall: 0.8184\n",
      "Epoch 59/90\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 3.8854 - precision: 0.9453 - recall: 0.7843 - val_loss: 3.7685 - val_precision: 0.9256 - val_recall: 0.8094\n",
      "Epoch 60/90\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 3.4582 - precision: 0.9601 - recall: 0.7987 - val_loss: 3.6882 - val_precision: 0.9654 - val_recall: 0.8139\n",
      "Epoch 61/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.3825 - precision: 0.9666 - recall: 0.7998 - val_loss: 3.6795 - val_precision: 0.9678 - val_recall: 0.8094\n",
      "Epoch 62/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.3386 - precision: 0.9719 - recall: 0.8031 - val_loss: 3.6692 - val_precision: 0.9705 - val_recall: 0.8117\n",
      "Epoch 63/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 6.3301 - precision: 0.9442 - recall: 0.7301 - val_loss: 4.4816 - val_precision: 0.9284 - val_recall: 0.7556\n",
      "Epoch 64/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.9971 - precision: 0.9469 - recall: 0.7500 - val_loss: 4.2882 - val_precision: 0.9333 - val_recall: 0.7848\n",
      "Epoch 65/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.9050 - precision: 0.9469 - recall: 0.7688 - val_loss: 3.8651 - val_precision: 0.9349 - val_recall: 0.8049\n",
      "Epoch 66/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.6727 - precision: 0.9547 - recall: 0.7699 - val_loss: 3.9420 - val_precision: 0.9489 - val_recall: 0.7915\n",
      "Epoch 67/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.5750 - precision: 0.9579 - recall: 0.7799 - val_loss: 3.9395 - val_precision: 0.9370 - val_recall: 0.8004\n",
      "Epoch 68/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.6900 - precision: 0.9568 - recall: 0.7843 - val_loss: 4.1679 - val_precision: 0.9215 - val_recall: 0.8161\n",
      "Epoch 69/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.6608 - precision: 0.9559 - recall: 0.7920 - val_loss: 4.1144 - val_precision: 0.9508 - val_recall: 0.8229\n",
      "Epoch 70/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.4748 - precision: 0.9611 - recall: 0.7920 - val_loss: 3.8962 - val_precision: 0.9554 - val_recall: 0.8161\n",
      "Epoch 71/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.4667 - precision: 0.9573 - recall: 0.7942 - val_loss: 3.7446 - val_precision: 0.9608 - val_recall: 0.8251\n",
      "Epoch 72/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.3381 - precision: 0.9626 - recall: 0.7965 - val_loss: 3.9615 - val_precision: 0.9471 - val_recall: 0.8430\n",
      "Epoch 73/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.2645 - precision: 0.9644 - recall: 0.8086 - val_loss: 3.7699 - val_precision: 0.9589 - val_recall: 0.8363\n",
      "Epoch 74/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.8941 - precision: 0.9562 - recall: 0.7965 - val_loss: 3.9924 - val_precision: 0.9623 - val_recall: 0.8004\n",
      "Epoch 75/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.4062 - precision: 0.9530 - recall: 0.8075 - val_loss: 3.9963 - val_precision: 0.9556 - val_recall: 0.8206\n",
      "Epoch 76/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.2356 - precision: 0.9597 - recall: 0.8175 - val_loss: 5.1653 - val_precision: 0.9106 - val_recall: 0.8677\n",
      "Epoch 77/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.6937 - precision: 0.9602 - recall: 0.8009 - val_loss: 3.9183 - val_precision: 0.9508 - val_recall: 0.8229\n",
      "Epoch 78/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.2440 - precision: 0.9620 - recall: 0.8131 - val_loss: 3.7579 - val_precision: 0.9585 - val_recall: 0.8296\n",
      "Epoch 79/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.2548 - precision: 0.9609 - recall: 0.8153 - val_loss: 4.0329 - val_precision: 0.9585 - val_recall: 0.8296\n",
      "Epoch 80/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.1979 - precision: 0.9686 - recall: 0.8186 - val_loss: 3.8618 - val_precision: 0.9529 - val_recall: 0.8610\n",
      "Epoch 81/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.1522 - precision: 0.9627 - recall: 0.8274 - val_loss: 3.8166 - val_precision: 0.9557 - val_recall: 0.8229\n",
      "Epoch 82/90\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 3.2256 - precision: 0.9586 - recall: 0.8197 - val_loss: 3.5716 - val_precision: 0.9514 - val_recall: 0.8341\n",
      "Epoch 83/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.1683 - precision: 0.9634 - recall: 0.8164 - val_loss: 3.8031 - val_precision: 0.9443 - val_recall: 0.8363\n",
      "Epoch 84/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.0497 - precision: 0.9635 - recall: 0.8175 - val_loss: 4.1556 - val_precision: 0.9148 - val_recall: 0.8430\n",
      "Epoch 85/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.1358 - precision: 0.9610 - recall: 0.8175 - val_loss: 3.8560 - val_precision: 0.9634 - val_recall: 0.8251\n",
      "Epoch 86/90\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 3.0377 - precision: 0.9736 - recall: 0.8175 - val_loss: 5.7371 - val_precision: 0.9540 - val_recall: 0.8363\n",
      "Epoch 87/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 2.9587 - precision: 0.9725 - recall: 0.8208 - val_loss: 5.6223 - val_precision: 0.9244 - val_recall: 0.8498\n",
      "Epoch 88/90\n",
      "189/189 [==============================] - 0s 3ms/step - loss: 3.0130 - precision: 0.9648 - recall: 0.8197 - val_loss: 5.6048 - val_precision: 0.9466 - val_recall: 0.8341\n",
      "Epoch 89/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.2630 - precision: 0.9674 - recall: 0.8197 - val_loss: 7.1199 - val_precision: 0.9330 - val_recall: 0.8430\n",
      "Epoch 90/90\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 3.0649 - precision: 0.9688 - recall: 0.8230 - val_loss: 6.7741 - val_precision: 0.9513 - val_recall: 0.8318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e02a8cd5bd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=90)  #, class_weight=class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yBjBmJ3LRST"
   },
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "Evaluate the model's performance over the validation data (X_test and y_test). Use the model's predictions (y_test_pred) and compare them to the actual labels (y_test). In this cell we print the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rj6j2AZCIDSe",
    "outputId": "a3881412-17de-470f-de97-d6752f73e398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 1ms/step\n",
      "Accuracy: 96.84%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_test_pred = model.predict(X_test).round()\n",
    "\n",
    "acc = metrics.accuracy_score(y_test_pred, y_test)\n",
    "\n",
    "print(f'Accuracy: {acc:,.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a `classification report` which will provide a more detailed analysis of the model's performance. It includes metrics such as `precision`, `recall`, and `f1-score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xd3EcAwtRs_N",
    "outputId": "a6b345f2-17b7-4949-c9d6-039caeda08bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      2584\n",
      "         1.0       0.83      0.95      0.89       390\n",
      "\n",
      "    accuracy                           0.97      2974\n",
      "   macro avg       0.91      0.96      0.93      2974\n",
      "weighted avg       0.97      0.97      0.97      2974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Create a confusion matrix which will provide a visual representation of the model's performance. It shows the number of true positives, true negatives, false positives, and false negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "wRjkKQ0szWKT",
    "outputId": "2053d75c-b81a-46e4-f28e-4c72b48dbfce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat=confusion_matrix(y_test_pred,y_test)\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                conf_mat.flatten()]\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "          zip(group_names,group_counts)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(conf_mat, annot=labels, fmt=\"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
